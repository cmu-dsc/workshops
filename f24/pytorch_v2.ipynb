{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH20Mfp9m_D-"
      },
      "source": [
        "Tensors\n",
        "=======\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays\n",
        "and matrices. In PyTorch, we use tensors to encode the inputs and\n",
        "outputs of a model, as well as the model's parameters."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JLZ5V07rs59a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing a Tensor\n",
        "=====================\n"
      ],
      "metadata": {
        "id": "LaReNxgKtild"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Right from data\n",
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "#From a NumPy array\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "j0Kptdb5tjlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "#Generate a 2x2 tensor matrix using:\n",
        "#1. all random numbers\n",
        "#2. all ones\n",
        "#3. all zeros"
      ],
      "metadata": {
        "id": "A04ICAP3t3hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attributes of a Tensor\n",
        "======================\n",
        "Tensor attributes describe their shape, datatype, and the device on\n",
        "which they are stored.\n"
      ],
      "metadata": {
        "id": "0usB7XoZuNc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "#For any one of the previously generated tensors, find the\n",
        "#Shape of the Tensor\n",
        "#Datatype of the Tensor\n",
        "#Device of the tensor"
      ],
      "metadata": {
        "id": "QO6FrZAsuRST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operations on Tensors\n",
        "====================="
      ],
      "metadata": {
        "id": "3rgqUGR-uitu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")"
      ],
      "metadata": {
        "id": "3vS0eeq4ulh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample operations"
      ],
      "metadata": {
        "id": "eL0vb9N0u4nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#indexing and slicing\n",
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "#TODO: Print the last column\n",
        "tensor[:,1] = 0\n",
        "print(tensor)\n",
        "\n",
        "#joining tensors\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH3EPULPu6Bd",
        "outputId": "0a75059b-6697-4a6c-c791-3ebefe7dfc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arithmetic operations"
      ],
      "metadata": {
        "id": "UUV2FLsgDm2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "# TODO: compute the element-wise product\n"
      ],
      "metadata": {
        "id": "y2MH8fowvUvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In place operations"
      ],
      "metadata": {
        "id": "5DdBUiehDr55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "nhJXcXZBvh6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE:\n",
        "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate lossof history. Hence, their use is discouraged."
      ],
      "metadata": {
        "id": "jKIGZMbgvlYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets & DataLoaders\n",
        "======================\n",
        "\n",
        "PyTorch provides two data\n",
        "primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset`\n",
        "that allow you to use pre-loaded datasets as well as your own data.\n",
        "`Dataset` stores the samples and their corresponding labels, and\n",
        "`DataLoader` wraps an iterable around the `Dataset` to enable easy\n",
        "access to the samples."
      ],
      "metadata": {
        "id": "6Uusuu32vrrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a Dataset:\n",
        "\n",
        "Here is an example of how to load the Fashion-MNIST dataset from TorchVision. Fashion-MNIST is a dataset of Zalando's article images consisting of 60,000 training examples and 10,000 test examples. Each example comprises a 28Ã—28 grayscale image and an associated label from one of 10 classes.\n",
        "\n",
        "We load the FashionMNIST Dataset with the following parameters:\n",
        "\n",
        ": - root is the path where the train/test data is stored, - train specifies training or test dataset, - download=True downloads the data from the internet if it's not available at root. - transform and target_transform specify the feature and label transformations"
      ],
      "metadata": {
        "id": "kfKCOMxWvwed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "vgHf_KYDvsXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can index `Datasets` manually like a list: `training_data[index]`. We\n",
        "use `matplotlib` to visualize some samples in our training data."
      ],
      "metadata": {
        "id": "F8L7nbwfEvIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "25EMuE_8wTV_",
        "outputId": "71d7bb19-d2a5-48b4-8a2d-a5bbb9f7bdb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e92ed7dde4d0>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Ankle Boot\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Custom Dataset\n",
        "========================================\n",
        "\n",
        "A custom Dataset class must implement three functions:\n",
        "[\\_\\_init\\_\\_]{.title-ref}, [\\_\\_len\\_\\_]{.title-ref}, and\n",
        "[\\_\\_getitem\\_\\_]{.title-ref}. The\n",
        "FashionMNIST images are stored in a directory `img_dir`, and their\n",
        "labels are stored separately in a CSV file `annotations_file`.\n"
      ],
      "metadata": {
        "id": "2aDqqB50wqvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "#TODO: Implement the __init__ and __len__ methods\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "y-5vx3TNwq7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing data for training with DataLoaders\n",
        "=================================================\n",
        "\n",
        "The `Dataset` retrieves our dataset\\'s features and labels one sample at\n",
        "a time. While training a model, we typically want to pass samples in\n",
        "\\\"minibatches\\\", reshuffle the data at every epoch to reduce model\n",
        "overfitting, and use Python\\'s `multiprocessing` to speed up data\n",
        "retrieval.\n",
        "\n",
        "`DataLoader` is an iterable that abstracts this complexity for us in an\n",
        "easy API."
      ],
      "metadata": {
        "id": "HGbMNZilxTna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "GPpakiNpxNB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms\n",
        "==========\n",
        "\n",
        "Data does not always come in its final processed form that is required\n",
        "for training machine learning algorithms. you can use **transforms** to\n",
        "perform some manipulation of the data and make it suitable for training.\n",
        "\n",
        "All TorchVision datasets have two parameters -`transform` to modify the\n",
        "features and `target_transform` to modify the labels - that accept\n",
        "callables containing the transformation logic. The torchvision.transforms\n",
        "module offers several commonly-used transforms out of the box.\n",
        "\n",
        "The FashionMNIST features are in PIL Image format, and the labels are\n",
        "integers. For training, we need the features as normalized tensors, and\n",
        "the labels as one-hot encoded tensors. To make these transformations, we\n",
        "use `ToTensor` and `Lambda`.\n"
      ],
      "metadata": {
        "id": "hvSvOMPDxv3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    #TODO: transform the labels\n",
        ")"
      ],
      "metadata": {
        "id": "6HmkAff4yFPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Neural Network\n",
        "========================\n",
        "\n",
        "Neural networks comprise of layers/modules that perform operations on\n",
        "data. The [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace\n",
        "provides all the building blocks you need to build your own neural\n",
        "network. Every module in PyTorch subclasses the\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "A neural network is a module itself that consists of other modules\n",
        "(layers). This nested structure allows for building and managing complex\n",
        "architectures easily.\n",
        "\n",
        "In the following sections, we\\'ll build a neural network to classify\n",
        "images in the FashionMNIST dataset.\n"
      ],
      "metadata": {
        "id": "LkoH4Gltyqq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "tEtkikiRyrKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Attempting to use the gpu if available\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH8M5nmzys5d",
        "outputId": "19104b0e-1c60-4c01-cfb8-132e2aed8156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Class\n",
        "================\n",
        "\n",
        "We define our neural network by subclassing `nn.Module`, and initialize\n",
        "the neural network layers in `__init__`. Every `nn.Module` subclass\n",
        "implements the operations on input data in the `forward` method.\n"
      ],
      "metadata": {
        "id": "eK0JZ2DSzVeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            #TODO: define the NN with 6 layers(in this order):\n",
        "            '''\n",
        "            1 linear layer(dimensions: 28*28, 512)\n",
        "            1 relu activation layer\n",
        "            1 linear layer(dimensions: 512, 512)\n",
        "            1 relu activation layer\n",
        "            1 linear layer(dimensions: 512, 10)'''\n",
        "            #BONUS:Feel free to tinker with the architecture of the model to see if it improves results after completing the colab\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "0quYHgJBzV8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AePeKaR_KlAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using PyTorch and NN's in a general ML workflow\n",
        "========================\n"
      ],
      "metadata": {
        "id": "mBO_1sTaJCUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the model on a single example:\n",
        "========================\n",
        "\n",
        "\n",
        "To use the model, we pass it the input data. This executes the model\\'s\n",
        "`forward`. Do not call `model.forward()` directly!\n",
        "\n",
        "Calling the model on the input returns a 2-dimensional tensor with dim=0\n",
        "corresponding to each output of 10 raw predicted values for each class,\n",
        "and dim=1 corresponding to the individual values of each output. We get\n",
        "the prediction probabilities by passing it through an instance of the\n",
        "`nn.Softmax` module.\n"
      ],
      "metadata": {
        "id": "jDGHoo1x0BXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#TODO: Declare an instance of the model\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "#TODO: Call the model on the data\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "bGX7jzgvzd3M",
        "outputId": "179f8ee3-3168-4b9a-8df3-63525bf4a639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'logits' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-751717105f03>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Call the model on the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred_probab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_probab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted class: {y_pred}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'logits' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the model on an entire dataset:\n",
        "========================\n"
      ],
      "metadata": {
        "id": "pwX_dZuPJRAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters\n",
        "===============\n",
        "\n",
        "Hyperparameters are adjustable parameters that let you control the model\n",
        "optimization process. Different hyperparameter values can impact model\n",
        "training and convergence rates ([read\n",
        "more](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)\n",
        "about hyperparameter tuning)\n",
        "\n",
        "We define the following hyperparameters for training:\n",
        "\n",
        ":   -   **Number of Epochs** - the number times to iterate over the\n",
        "        dataset\n",
        "    -   **Batch Size** - the number of data samples propagated through\n",
        "        the network before the parameters are updated\n",
        "    -   **Learning Rate** - how much to update models parameters at each\n",
        "        batch/epoch. Smaller values yield slow learning speed, while\n",
        "        large values may result in unpredictable behavior during\n",
        "        training.\n"
      ],
      "metadata": {
        "id": "NIeAb5De2nau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "#BONUS: Feel free to tinker with the Hyperparameters to see if you can improve model performance!"
      ],
      "metadata": {
        "id": "h4hujFu80NmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization Loop\n",
        "=================\n",
        "\n",
        "Once we set our hyperparameters, we can then train and optimize our\n",
        "model with an optimization loop. Each iteration of the optimization loop\n",
        "is called an **epoch**.\n",
        "\n",
        "Each epoch consists of two main parts:\n",
        "\n",
        ":   -   **The Train Loop** - iterate over the training dataset and try\n",
        "        to converge to optimal parameters.\n",
        "    -   **The Validation/Test Loop** - iterate over the test dataset to\n",
        "        check if model performance is improving."
      ],
      "metadata": {
        "id": "YuzSCWq27J2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function to crossentropy loss and optimzer to SGD\n",
        "loss_fn =_\n",
        "optimizer =_"
      ],
      "metadata": {
        "id": "t3z-WR4M7Vid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # TODO: Complete the backpropagation cycle\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "WpYnn9B87e_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            #TODO: Increment the test lost and correct variables\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "4fSsLLwf7g1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    #implement the train and test steps for each epoch\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "OPmF8oaa7yvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing model output"
      ],
      "metadata": {
        "id": "QHouFErDHIHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "img = next(iter(test_data))\n",
        "img_t = torch.FloatTensor(img[0])[0, :, :]\n",
        "img_o = torchvision.transforms.ToPILImage()(img_t.to('cpu'))\n",
        "img_o"
      ],
      "metadata": {
        "id": "-Vw4BQSPF5oh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}